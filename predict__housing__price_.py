# -*- coding: utf-8 -*-
"""Predict_ Housing_ Price .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16eMNxM6AQbLX7ewt44uQSOqtE7GqvFjI
"""

from keras.datasets import boston_housing 
(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()

print(len(train_data))
print(len(test_data))

print(train_data[10])
print(train_labels[10])

import numpy as np

mean=train_data.mean(axis=0)

std= train_data.std(axis=0)

train_data= (train_data-mean)/std

mean=test_data.mean(axis=0)

std= test_data.std(axis=0)

test_data= (test_data-mean)/std

print(train_data[10])

print(test_data[10])

"""Let's check one of the sentences:

## Build the network
"""

from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(13,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1))

model.compile(optimizer='rmsprop', 
              loss='mse', 
              metrics=['mae'])

history = model.fit(train_data, 
                    train_labels, 
                    epochs=400, 
                    batch_size=1)

print model.predict()

"""## Plotting the results"""

# %matplotlib inline
import matplotlib.pyplot as plt

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training loss')

plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()

acc = history.history['acc']
val_acc = history.history['val_acc']

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

"""We are overfitting! Let's retrain the same model with 9 epochs:"""

from keras import models
from keras import layers
model1 = models.Sequential()



model1.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model1.add(layers.Dense(64, activation='relu'))
model1.add(layers.Dense(46, activation='softmax'))

model1.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

k2=model1.fit(partial_x_train, 
          partial_y_train, 
          epochs=8, 
          batch_size=512, 
          validation_data=(x_val, y_val))

results = model1.evaluate(x_test, one_hot_test_labels)

print(results)

# %matplotlib inline
import matplotlib.pyplot as plt

loss =k2.history['loss']
val_loss = k2.history['val_loss']

epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()